{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMCDPXk8wVI6nmEl3cxErvk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Devg1804/PDF_q-a-Llamaindex-Llama2/blob/main/chat_with_PDF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Chat with your PDF using LlamaIndex,enhanced with the Llama2 model API using Gradient's LLM solution, seamlessly merge it with DataStax's Apache Cassandra as a vector database and Streamlit for web app.**\n",
        "\n"
      ],
      "metadata": {
        "id": "aT1US7PFkZZa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YN7KfXxves9J"
      },
      "outputs": [],
      "source": [
        "Gradiant_workspace_id = \"d2293e23-346b-4bb2-8fd1-aa2ddfddd185_workspace\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Gradiant_Token = \"WksfesNfS69kkSQYaqMU9CzNVbAWfDPY\""
      ],
      "metadata": {
        "id": "VEicc6ywfxJJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installation"
      ],
      "metadata": {
        "id": "3svG8BYGlPAJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q cassandra-driver\n",
        "!pip install -q cassio>=0.1.1\n",
        "!pip install -q gradientai --upgrade\n",
        "!pip install -q llama-index\n",
        "!pip install -q pypdf\n",
        "!pip install -q tiktoken==0.4.0"
      ],
      "metadata": {
        "id": "emU_T35xgeYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import OS & JSON Modules"
      ],
      "metadata": {
        "id": "3yJHmY_RmSHK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ['GRADIENT_ACCESS_TOKEN'] = userdata.get('GRADIENT_ACCESS_TOKEN')\n",
        "os.environ['GRADIENT_WORKSPACE_ID'] = userdata.get('GRADIENT_WORKSPACE_ID')"
      ],
      "metadata": {
        "id": "OKvIzC94gksb"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Cassandra & llama Index"
      ],
      "metadata": {
        "id": "ZJYqGHZKmaUP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from cassandra.auth import PlainTextAuthProvider\n",
        "from cassandra.cluster import Cluster\n",
        "from llama_index import ServiceContext\n",
        "from llama_index import set_global_service_context\n",
        "from llama_index import VectorStoreIndex, SimpleDirectoryReader, StorageContext\n",
        "from llama_index.embeddings import GradientEmbedding\n",
        "from llama_index.llms import GradientBaseModelLLM\n",
        "from llama_index.vector_stores import CassandraVectorStore"
      ],
      "metadata": {
        "id": "VgvykiaEmRyo"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cassandra\n",
        "print (cassandra.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7SICrrounuBr",
        "outputId": "c40f7f56-475c-48bb-eb93-f929deaf54d3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.29.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connect to the VectorDB"
      ],
      "metadata": {
        "id": "TgzPAa46n1Vr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This secure connect bundle is autogenerated when you donwload your SCB,\n",
        "# if yours is different update the file name below\n",
        "cloud_config= {\n",
        "  'secure_connect_bundle': 'secure-connect-pdfquery-db.zip'\n",
        "}\n",
        "\n",
        "# This token json file is autogenerated when you donwload your token,\n",
        "# if yours is different update the file name below\n",
        "with open(\"PdfQuery_db-token.json\") as f:\n",
        "    secrets = json.load(f)\n",
        "\n",
        "CLIENT_ID = secrets[\"clientId\"]\n",
        "CLIENT_SECRET = secrets[\"secret\"]\n",
        "\n",
        "auth_provider = PlainTextAuthProvider(CLIENT_ID, CLIENT_SECRET)\n",
        "cluster = Cluster(cloud=cloud_config, auth_provider=auth_provider)\n",
        "session = cluster.connect()\n",
        "\n",
        "row = session.execute(\"select release_version from system.local\").one()\n",
        "if row:\n",
        "  print(row[0])\n",
        "else:\n",
        "  print(\"An error occurred.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOddHLwPnyHz",
        "outputId": "6ef174aa-4292-4bc8-de42-34d092d4c3ab"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:cassandra.cluster:Downgrading core protocol version from 66 to 65 for 76f4aada-1151-4fc4-bfc3-0fe2d62e9db8-us-east1.db.astra.datastax.com:29042:01bec412-40f1-4235-bb24-5e11b2020c3a. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n",
            "WARNING:cassandra.cluster:Downgrading core protocol version from 65 to 5 for 76f4aada-1151-4fc4-bfc3-0fe2d62e9db8-us-east1.db.astra.datastax.com:29042:01bec412-40f1-4235-bb24-5e11b2020c3a. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n",
            "ERROR:cassandra.connection:Closing connection <AsyncoreConnection(137706936360848) 76f4aada-1151-4fc4-bfc3-0fe2d62e9db8-us-east1.db.astra.datastax.com:29042:01bec412-40f1-4235-bb24-5e11b2020c3a> due to protocol error: Error from server: code=000a [Protocol error] message=\"Beta version of the protocol used (5/v5-beta), but USE_BETA flag is unset\"\n",
            "WARNING:cassandra.cluster:Downgrading core protocol version from 5 to 4 for 76f4aada-1151-4fc4-bfc3-0fe2d62e9db8-us-east1.db.astra.datastax.com:29042:01bec412-40f1-4235-bb24-5e11b2020c3a. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.0.11-c7d4aa9d7ae5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the Gradient's Model Adapter for LLAMA-2"
      ],
      "metadata": {
        "id": "r5hn8oaPpk1u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = GradientBaseModelLLM(\n",
        "    base_model_slug=\"llama2-7b-chat\",\n",
        "    max_tokens=400,\n",
        ")"
      ],
      "metadata": {
        "id": "OZxk5-q0pAkq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Configure Gradient embeddings"
      ],
      "metadata": {
        "id": "tn4dYV4CpoMY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embed_model = GradientEmbedding(\n",
        "    gradient_access_token = os.environ[\"GRADIENT_ACCESS_TOKEN\"],\n",
        "    gradient_workspace_id = os.environ[\"GRADIENT_WORKSPACE_ID\"],\n",
        "    gradient_model_slug=\"bge-large\",\n",
        ")"
      ],
      "metadata": {
        "id": "apJVp6YFp6oS"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "service_context = ServiceContext.from_defaults(\n",
        "    llm = llm,\n",
        "    embed_model = embed_model,\n",
        "    chunk_size=256,\n",
        ")\n",
        "\n",
        "set_global_service_context(service_context)"
      ],
      "metadata": {
        "id": "hEi2exjKqBEJ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the PDFs"
      ],
      "metadata": {
        "id": "Kc5sJaZ9poWJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documents = SimpleDirectoryReader(\"/content/Documents\").load_data()\n",
        "print(f\"Loaded {len(documents)} document(s).\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5lzzfLIqNL7",
        "outputId": "9b54134e-4a79-4a35-c39f-e57a4d778be3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 154 document(s).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup and Query Index"
      ],
      "metadata": {
        "id": "0a0dnZSvpoc6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index = VectorStoreIndex.from_documents(documents,\n",
        "                                        service_context=service_context)\n",
        "query_engine = index.as_query_engine()\n"
      ],
      "metadata": {
        "id": "ScL6TStjpzzW"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\"What is Attention?\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7ZggnS9qw7c",
        "outputId": "80f3f8be-2c5c-4067-e3a7-c1a00f5d7101"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Attention is a mechanism that helps improve the performance of neural machine translation applications. It is a concept that helps the model focus on the most relevant parts of the input sequence when generating the output sequence. In other words, attention allows the model to selectively focus on certain parts of the input when making predictions, rather than using the entire input equally.\n",
            "\n",
            "Explanation:\n",
            "Attention was introduced in the paper \"Attention is All You Need\" by Vaswani et al. in 2017. It is a key component of the Transformer architecture, which is a popular neural network model for machine translation tasks. Attention allows the model to selectively focus on certain parts of the input sequence when generating the output sequence, rather than using the entire input equally. This helps the model to better capture long-range dependencies in the input sequence and improve its overall performance.\n",
            "\n",
            "In the context of the passage, attention is mentioned as a mechanism that helps improve the performance of neural machine translation applications. The passage also explains how attention works and how it is used in the Transformer architecture.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O2uN0pdUrd5H"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}